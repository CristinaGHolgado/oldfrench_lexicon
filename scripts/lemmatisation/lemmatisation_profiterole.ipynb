{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIGo9GqL0A_c"
      },
      "source": [
        "## Install Pie & download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuR1CPynwcHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5360eb5f-19a1-4c55-a944-05cbb28c4be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlp-pie\n",
            "  Downloading nlp_pie-0.3.8-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 20 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 30 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 84 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from nlp-pie) (1.1.0)\n",
            "Collecting typing<4.0\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from nlp-pie) (4.2.6)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from nlp-pie) (7.1.2)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from nlp-pie) (3.6.0)\n",
            "Collecting terminaltables==3.1.0\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "Collecting torch<=1.7.1,>=1.3.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting numpy<1.18.0,>=1.14.3\n",
            "  Downloading numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting JSON-minify>=0.3.0\n",
            "  Downloading JSON_minify-0.3.0-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting scikit-learn<0.23.0,>=0.19.1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 37.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.1b3\n",
            "  Downloading PyYAML-5.1b3.tar.gz (273 kB)\n",
            "\u001b[K     |████████████████████████████████| 273 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.23.3 in /usr/local/lib/python3.7/dist-packages (from nlp-pie) (4.63.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->nlp-pie) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->nlp-pie) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->nlp-pie) (5.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.23.0,>=0.19.1->nlp-pie) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.3.1->nlp-pie) (3.10.0.2)\n",
            "Building wheels for collected packages: pyyaml, terminaltables, typing\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1b3-cp37-cp37m-linux_x86_64.whl size=44132 sha256=3cc7cec2bc81a5a5d1c6ceadbf2c871296a2418c1c162acda9cdbc9f70d4a8c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/c7/d2/c0ba4c4313eb65117691e80efddfe68406f95b50762c8565d1\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=6d7c0e36e5f902ba8702bda0c4c46e94361d6d48ce2db0f2fe157885a12e413e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=4ba9b9ea98df8efbd06f2879691162ef3e7ef5de2c1ec57042d07d9c485b0257\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built pyyaml terminaltables typing\n",
            "Installing collected packages: numpy, typing, torch, terminaltables, scikit-learn, pyyaml, JSON-minify, nlp-pie\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.17.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.17.5 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.17.5 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.17.5 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed JSON-minify-0.3.0 nlp-pie-0.3.8 numpy-1.17.5 pyyaml-5.1b3 scikit-learn-0.22.2.post1 terminaltables-3.1.0 torch-1.7.1 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install nlp-pie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYud_WFhEcoS",
        "outputId": "7f4ca1c2-8eee-4817-8271-c05fc5676fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pie\n",
            "Current working directory: \n",
            "commit_build.py        __init__.py\t    scripts\t    utils.py\n",
            "constants.py\t       models\t\t    settings.py     webapp\n",
            "data\t\t       optimize.py\t    tagger.py\n",
            "default_settings.json  pretrain_encoder.py  torch_utils.py\n",
            "initialization.py      __pycache__\t    trainer.py\n"
          ]
        }
      ],
      "source": [
        "# set working directory to Pie (or change)\n",
        "%cd /usr/local/lib/python3.7/dist-packages/pie\n",
        "print('Current working directory: ')\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZd-qT7y0NqA",
        "outputId": "103c772d-d19c-4868-a661-930c4b181554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=ffde57fe8e4b09b1003a1a8cdf8e450ffed3913b9fe5385acd023f7a3027d9fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Downloading train_data\n",
            "Downloading dev_data\n",
            "Downloading test_data\n"
          ]
        }
      ],
      "source": [
        "## Download traning/dev/test data\n",
        "!pip install wget\n",
        "import wget\n",
        "\n",
        "urls= {'train_data':'https://sharedocs.huma-num.fr/wl/?id=LVfEryNatUmIOSrcv79qLt7Vh9xQcP5G&fmode=open',\n",
        "       'dev_data': 'https://sharedocs.huma-num.fr/wl/?id=NP9ubphyOqW1kHf5E6EKdq6F4USxFLC6&fmode=open',\n",
        "       'test_data': 'https://sharedocs.huma-num.fr/wl/?id=5bNmeXMzMVVOR11huaOx6aiYFVzRsRNf&fmode=open'}\n",
        "\n",
        "for k, v in urls.items():\n",
        "  print('Downloading', k)\n",
        "  wget.download(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK4DY5x0za3Q"
      },
      "source": [
        "## Train lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgeKktQa96GV",
        "outputId": "f73f81d2-8190-41d9-bcb5-7228825f9a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "WARNING:root:\n",
            "It seems like you downloaded `pie` instead of git-cloning it or installing it with pip.\n",
            "We won't be able to check compatibility between pretrained models and `pie` version.\n",
            "\n",
            "\n",
            "::: Loaded Config :::\n",
            "\n",
            "batch_size: 50\n",
            "breakline_data: $.\n",
            "breakline_ref: ''\n",
            "buffer_size: 10000\n",
            "cache_dataset: false\n",
            "cell: LSTM\n",
            "cemb_dim: 150\n",
            "cemb_layers: 1\n",
            "cemb_type: rnn\n",
            "char_bos: true\n",
            "char_eos: true\n",
            "char_lower: false\n",
            "char_max_size: 500\n",
            "char_min_freq: 1\n",
            "checks_per_epoch: 1\n",
            "clip_norm: 5.0\n",
            "config_path: default_settings.json\n",
            "custom_cemb_cell: false\n",
            "dev_path: development_bfm.tsv\n",
            "device: cpu\n",
            "drop_diacritics: false\n",
            "dropout: 0.0\n",
            "epochs: 500\n",
            "factor: 1\n",
            "freeze_embeddings: false\n",
            "header: true\n",
            "hidden_size: 300\n",
            "include_lm: false\n",
            "init_rnn: default\n",
            "input_path: training_bfm.tsv\n",
            "linear_layers: 1\n",
            "lm_schedule:\n",
            "  factor: 0.5\n",
            "  mode: min\n",
            "  patience: 2\n",
            "  weight: 0.2\n",
            "lm_shared_softmax: true\n",
            "load_pretrained_embeddings: ''\n",
            "load_pretrained_encoder: ''\n",
            "lr: 0.001\n",
            "lr_factor: 0.75\n",
            "lr_patience: 2\n",
            "max_sent_len: 30\n",
            "max_sents: 10000\n",
            "merge_type: concat\n",
            "min_lr: 1.0e-06\n",
            "min_weight: 0\n",
            "minimize_pad: false\n",
            "modelname: model\n",
            "modelpath: ./\n",
            "num_layers: 1\n",
            "optimizer: Adam\n",
            "patience: 100\n",
            "pretrain_embeddings: false\n",
            "report_freq: 10\n",
            "run_test: false\n",
            "scorer: general\n",
            "sep: \"\\t\"\n",
            "shuffle: true\n",
            "task_defaults:\n",
            "  context: sentence\n",
            "  decoder: linear\n",
            "  layer: -1\n",
            "  level: token\n",
            "tasks:\n",
            "- context: none\n",
            "  decoder: attentional\n",
            "  default: copy\n",
            "  layer: -1\n",
            "  level: char\n",
            "  name: lemma\n",
            "  read_only: false\n",
            "  schedule:\n",
            "    patience: 2\n",
            "    threshold: 0.001\n",
            "  settings:\n",
            "    bos: true\n",
            "    eos: true\n",
            "    lower: true\n",
            "  target: true\n",
            "tasks_order:\n",
            "- lemma\n",
            "- pos\n",
            "test_path: test_bfm.tsv\n",
            "threshold: 0\n",
            "utfnorm: false\n",
            "utfnorm_type: NFKD\n",
            "verbose: true\n",
            "wemb_dim: 0\n",
            "word_dropout: 0.0\n",
            "word_lower: false\n",
            "word_max_size: 20000\n",
            "word_min_freq: 1\n",
            "\n",
            "Using seed: 103702\n",
            "::: Available tasks :::\n",
            "\n",
            "- pos\n",
            "- cattex\n",
            "- lemma\n",
            "\n",
            "::: Fitting data :::\n",
            "\n",
            "\n",
            "::: Vocabulary :::\n",
            "\n",
            "- word            types=19706/19706=1.00 tokens=284481/284481=1.00\n",
            "- char            types=83/83=1.00 tokens=1015725/1015725=1.00\n",
            "\n",
            "::: Tasks :::\n",
            "\n",
            "- lemma           target=lemma  level=char   vocab=66    \n",
            "\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "Model doesn't need sentence encoder, leaving uninitialized\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "::: Model :::\n",
            "\n",
            "SimpleModel(\n",
            "  (cemb): RNNEmbedding(\n",
            "    (emb): Embedding(87, 150, padding_idx=2)\n",
            "    (rnn): LSTM(150, 150, bidirectional=True)\n",
            "  )\n",
            "  (lemma_decoder): AttentionalDecoder(\n",
            "    (embs): Embedding(66, 150)\n",
            "    (rnn): LSTM(150, 300)\n",
            "    (attn): Attention(\n",
            "      (scorer): GeneralScorer(\n",
            "        (W_a): Linear(in_features=300, out_features=300, bias=False)\n",
            "      )\n",
            "      (linear_out): Linear(in_features=600, out_features=300, bias=False)\n",
            "    )\n",
            "    (proj): Linear(in_features=300, out_features=66, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "::: Model parameters :::\n",
            "\n",
            "1217616/1217616 trainable/total\n",
            "\n",
            "Starting training\n",
            "\n",
            "Evaluation check every 188/189 batches\n",
            "\n",
            "::: Task schedules :::\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"-inf\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "::: LR schedule :::\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.21it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 1.4539\n",
            "\n",
            "39it [00:43,  1.10s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.304    | 0.0055    | 0.0063 | 57031   |\n",
            "| known-tokens     | 0.381    | 0.0127    | 0.0139 | 45124   |\n",
            "| unknown-tokens   | 0.0119   | 0.0016    | 0.0023 | 11907   |\n",
            "| ambiguous-tokens | 0.2629   | 0.0218    | 0.0263 | 19042   |\n",
            "| unknown-targets  | 0.0018   | 0.0011    | 0.001  | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.304\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.22it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.9331\n",
            "\n",
            "39it [00:54,  1.40s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.4686   | 0.0303    | 0.0228 | 57031   |\n",
            "| known-tokens     | 0.5849   | 0.078     | 0.0636 | 45124   |\n",
            "| unknown-tokens   | 0.0282   | 0.0123    | 0.0083 | 11907   |\n",
            "| ambiguous-tokens | 0.5221   | 0.0838    | 0.0854 | 19042   |\n",
            "| unknown-targets  | 0.0096   | 0.0056    | 0.0045 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.4686\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:31,  1.24it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.8154\n",
            "\n",
            "39it [00:48,  1.24s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5129   | 0.0436    | 0.0327 | 57031   |\n",
            "| known-tokens     | 0.6329   | 0.1115    | 0.093  | 45124   |\n",
            "| unknown-tokens   | 0.0582   | 0.0218    | 0.0147 | 11907   |\n",
            "| ambiguous-tokens | 0.5371   | 0.0995    | 0.1024 | 19042   |\n",
            "| unknown-targets  | 0.0163   | 0.0104    | 0.0089 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5129\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:33,  1.17it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.7352\n",
            "\n",
            "39it [00:46,  1.19s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5366   | 0.0587    | 0.0442 | 57031   |\n",
            "| known-tokens     | 0.6565   | 0.147     | 0.1252 | 45124   |\n",
            "| unknown-tokens   | 0.0822   | 0.0313    | 0.0221 | 11907   |\n",
            "| ambiguous-tokens | 0.5511   | 0.1257    | 0.1217 | 19042   |\n",
            "| unknown-targets  | 0.0181   | 0.0124    | 0.0114 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5366\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:31,  1.23it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6972\n",
            "\n",
            "39it [00:45,  1.17s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5512   | 0.0722    | 0.0557 | 57031   |\n",
            "| known-tokens     | 0.6671   | 0.1784    | 0.1551 | 45124   |\n",
            "| unknown-tokens   | 0.112    | 0.0418    | 0.0307 | 11907   |\n",
            "| ambiguous-tokens | 0.5267   | 0.134     | 0.1317 | 19042   |\n",
            "| unknown-targets  | 0.0274   | 0.0189    | 0.0167 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5512\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.21it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6571\n",
            "\n",
            "39it [00:45,  1.17s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5814   | 0.0842    | 0.0652 | 57031   |\n",
            "| known-tokens     | 0.6991   | 0.2053    | 0.1807 | 45124   |\n",
            "| unknown-tokens   | 0.1351   | 0.0492    | 0.0369 | 11907   |\n",
            "| ambiguous-tokens | 0.5819   | 0.1505    | 0.1471 | 19042   |\n",
            "| unknown-targets  | 0.0334   | 0.0221    | 0.019  | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5814\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.21it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6238\n",
            "\n",
            "39it [00:47,  1.21s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6004   | 0.0921    | 0.0734 | 57031   |\n",
            "| known-tokens     | 0.7215   | 0.2322    | 0.2072 | 45124   |\n",
            "| unknown-tokens   | 0.1418   | 0.0542    | 0.0416 | 11907   |\n",
            "| ambiguous-tokens | 0.5918   | 0.1622    | 0.1599 | 19042   |\n",
            "| unknown-targets  | 0.0373   | 0.0243    | 0.0217 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6004\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:31,  1.24it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6036\n",
            "\n",
            "39it [00:46,  1.19s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.607    | 0.0979    | 0.0778 | 57031   |\n",
            "| known-tokens     | 0.7268   | 0.25      | 0.223  | 45124   |\n",
            "| unknown-tokens   | 0.1526   | 0.0587    | 0.0444 | 11907   |\n",
            "| ambiguous-tokens | 0.5885   | 0.1735    | 0.1676 | 19042   |\n",
            "| unknown-targets  | 0.0409   | 0.0273    | 0.0236 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.607\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:31,  1.22it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6041\n",
            "\n",
            "39it [00:48,  1.23s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6099   | 0.1097    | 0.0875 | 57031   |\n",
            "| known-tokens     | 0.7269   | 0.2696    | 0.2441 | 45124   |\n",
            "| unknown-tokens   | 0.1667   | 0.0655    | 0.0516 | 11907   |\n",
            "| ambiguous-tokens | 0.5611   | 0.174     | 0.1693 | 19042   |\n",
            "| unknown-targets  | 0.0461   | 0.0308    | 0.0252 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6099\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.21it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5800\n",
            "\n",
            "39it [00:48,  1.23s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6043   | 0.1132    | 0.0912 | 57031   |\n",
            "| known-tokens     | 0.7181   | 0.286     | 0.2602 | 45124   |\n",
            "| unknown-tokens   | 0.1731   | 0.0685    | 0.0538 | 11907   |\n",
            "| ambiguous-tokens | 0.5426   | 0.1928    | 0.1857 | 19042   |\n",
            "| unknown-targets  | 0.0494   | 0.0321    | 0.0263 | 3864    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"1\" mode=\"max\" weight=\"1.0\" best=\"0.6099\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"1\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "39it [00:32,  1.19it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5819\n",
            "\n",
            "39it [00:51,  1.32s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6097   | 0.1168    | 0.095  | 57031   |\n",
            "| known-tokens     | 0.7236   | 0.2999    | 0.2721 | 45124   |\n",
            "| unknown-tokens   | 0.1779   | 0.0691    | 0.0543 | 11907   |\n",
            "| ambiguous-tokens | 0.5613   | 0.1913    | 0.1851 | 19042   |\n",
            "| unknown-targets  | 0.0443   | 0.0269    | 0.023  | 3864    |\n",
            "\n",
            "Evaluating model on test set\n",
            "12it [00:21,  1.80s/it]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.7416   | 0.1768    | 0.1631 | 17420   |\n",
            "| known-tokens     | 0.8349   | 0.3578    | 0.3467 | 15007   |\n",
            "| unknown-tokens   | 0.1608   | 0.0816    | 0.0675 | 2413    |\n",
            "| ambiguous-tokens | 0.7142   | 0.2087    | 0.2118 | 5707    |\n",
            "| unknown-targets  | 0.0599   | 0.0253    | 0.0215 | 1186    |\n",
            "\n",
            "Saved best model to: [./model-lemma-2022_03_28-13_08_53.tar]\n",
            "39it [00:58,  1.50s/it]\n",
            "Bye!\n"
          ]
        }
      ],
      "source": [
        "!pie train default_settings.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW-ItCi6phok",
        "outputId": "32ec3d19-2396-4dde-c98d-b147f75862f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "WARNING:root:\n",
            "It seems like you downloaded `pie` instead of git-cloning it or installing it with pip.\n",
            "We won't be able to check compatibility between pretrained models and `pie` version.\n",
            "\n",
            "\n",
            "::: Loaded Config :::\n",
            "\n",
            "batch_size: 30\n",
            "breakline_data: $.\n",
            "breakline_ref: ''\n",
            "buffer_size: 10000\n",
            "cache_dataset: false\n",
            "cell: LSTM\n",
            "cemb_dim: 150\n",
            "cemb_layers: 1\n",
            "cemb_type: rnn\n",
            "char_bos: true\n",
            "char_eos: true\n",
            "char_lower: false\n",
            "char_max_size: 500\n",
            "char_min_freq: 1\n",
            "checks_per_epoch: 1\n",
            "clip_norm: 5.0\n",
            "config_path: default_settings.json\n",
            "custom_cemb_cell: false\n",
            "dev_path: development_bfm.tsv\n",
            "device: cpu\n",
            "drop_diacritics: false\n",
            "dropout: 0.0\n",
            "epochs: 200\n",
            "factor: 1\n",
            "freeze_embeddings: false\n",
            "header: true\n",
            "hidden_size: 300\n",
            "include_lm: false\n",
            "init_rnn: default\n",
            "input_path: training_bfm.tsv\n",
            "linear_layers: 1\n",
            "lm_schedule:\n",
            "  factor: 0.5\n",
            "  mode: min\n",
            "  patience: 2\n",
            "  weight: 0.2\n",
            "lm_shared_softmax: true\n",
            "load_pretrained_embeddings: ''\n",
            "load_pretrained_encoder: ''\n",
            "lr: 0.001\n",
            "lr_factor: 0.75\n",
            "lr_patience: 2\n",
            "max_sent_len: 30\n",
            "max_sents: 10000\n",
            "merge_type: concat\n",
            "min_lr: 0.0001\n",
            "min_weight: 0\n",
            "minimize_pad: false\n",
            "modelname: model\n",
            "modelpath: ./\n",
            "num_layers: 1\n",
            "optimizer: Adam\n",
            "patience: 100\n",
            "pretrain_embeddings: false\n",
            "report_freq: 10\n",
            "run_test: false\n",
            "scorer: general\n",
            "sep: \"\\t\"\n",
            "shuffle: true\n",
            "task_defaults:\n",
            "  context: sentence\n",
            "  decoder: linear\n",
            "  layer: -1\n",
            "  level: token\n",
            "tasks:\n",
            "- context: none\n",
            "  decoder: attentional\n",
            "  default: copy\n",
            "  layer: -1\n",
            "  level: char\n",
            "  name: lemma\n",
            "  read_only: false\n",
            "  schedule:\n",
            "    patience: 2\n",
            "    threshold: 0.001\n",
            "  settings:\n",
            "    bos: true\n",
            "    eos: true\n",
            "    lower: true\n",
            "  target: true\n",
            "tasks_order:\n",
            "- lemma\n",
            "- pos\n",
            "test_path: test_bfm.tsv\n",
            "threshold: 0\n",
            "utfnorm: false\n",
            "utfnorm_type: NFKD\n",
            "verbose: true\n",
            "wemb_dim: 0\n",
            "word_dropout: 0.0\n",
            "word_lower: false\n",
            "word_max_size: 20000\n",
            "word_min_freq: 1\n",
            "\n",
            "Using seed: 161335\n",
            "::: Available tasks :::\n",
            "\n",
            "- lemma\n",
            "- cattex\n",
            "- pos\n",
            "\n",
            "::: Fitting data :::\n",
            "\n",
            "\n",
            "::: Vocabulary :::\n",
            "\n",
            "- word            types=20000/21174=0.94 tokens=298826/300000=1.00\n",
            "- char            types=83/83=1.00 tokens=1073024/1073024=1.00\n",
            "\n",
            "::: Tasks :::\n",
            "\n",
            "- lemma           target=lemma  level=char   vocab=66    \n",
            "\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "Model doesn't need sentence encoder, leaving uninitialized\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "::: Model :::\n",
            "\n",
            "SimpleModel(\n",
            "  (cemb): RNNEmbedding(\n",
            "    (emb): Embedding(87, 150, padding_idx=2)\n",
            "    (rnn): LSTM(150, 150, bidirectional=True)\n",
            "  )\n",
            "  (lemma_decoder): AttentionalDecoder(\n",
            "    (embs): Embedding(66, 150)\n",
            "    (rnn): LSTM(150, 300)\n",
            "    (attn): Attention(\n",
            "      (scorer): GeneralScorer(\n",
            "        (W_a): Linear(in_features=300, out_features=300, bias=False)\n",
            "      )\n",
            "      (linear_out): Linear(in_features=600, out_features=300, bias=False)\n",
            "    )\n",
            "    (proj): Linear(in_features=300, out_features=66, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "::: Model parameters :::\n",
            "\n",
            "1217616/1217616 trainable/total\n",
            "\n",
            "Starting training\n",
            "\n",
            "Evaluation check every 332/333 batches\n",
            "\n",
            "::: Task schedules :::\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"-inf\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "::: LR schedule :::\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:31,  2.01it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 1.0988\n",
            "\n",
            "64it [00:40,  1.60it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.4208   | 0.0173    | 0.0153 | 57031   |\n",
            "| known-tokens     | 0.524    | 0.0419    | 0.0372 | 45124   |\n",
            "| unknown-tokens   | 0.0296   | 0.007     | 0.0068 | 11907   |\n",
            "| ambiguous-tokens | 0.4341   | 0.0568    | 0.0583 | 19042   |\n",
            "| unknown-targets  | 0.0047   | 0.0027    | 0.0022 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.4208\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.98it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.8375\n",
            "\n",
            "64it [00:43,  1.47it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5095   | 0.0399    | 0.0315 | 57031   |\n",
            "| known-tokens     | 0.6272   | 0.0982    | 0.0839 | 45124   |\n",
            "| unknown-tokens   | 0.0636   | 0.0187    | 0.0147 | 11907   |\n",
            "| ambiguous-tokens | 0.5417   | 0.0984    | 0.1019 | 19042   |\n",
            "| unknown-targets  | 0.0111   | 0.0073    | 0.0068 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5095\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.97it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.7393\n",
            "\n",
            "64it [00:47,  1.36it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.547    | 0.0592    | 0.0468 | 57031   |\n",
            "| known-tokens     | 0.6665   | 0.1536    | 0.1336 | 45124   |\n",
            "| unknown-tokens   | 0.0943   | 0.0302    | 0.0237 | 11907   |\n",
            "| ambiguous-tokens | 0.5604   | 0.1244    | 0.1278 | 19042   |\n",
            "| unknown-targets  | 0.0175   | 0.009     | 0.0079 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.547\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:33,  1.94it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6722\n",
            "\n",
            "64it [00:48,  1.31it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5678   | 0.0767    | 0.0623 | 57031   |\n",
            "| known-tokens     | 0.6838   | 0.1988    | 0.1774 | 45124   |\n",
            "| unknown-tokens   | 0.1284   | 0.0424    | 0.0339 | 11907   |\n",
            "| ambiguous-tokens | 0.5667   | 0.1403    | 0.1404 | 19042   |\n",
            "| unknown-targets  | 0.0169   | 0.0132    | 0.0116 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5678\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.98it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6353\n",
            "\n",
            "64it [00:46,  1.36it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5774   | 0.0885    | 0.0719 | 57031   |\n",
            "| known-tokens     | 0.6935   | 0.2323    | 0.2082 | 45124   |\n",
            "| unknown-tokens   | 0.1372   | 0.0488    | 0.0391 | 11907   |\n",
            "| ambiguous-tokens | 0.5521   | 0.1574    | 0.1551 | 19042   |\n",
            "| unknown-targets  | 0.0247   | 0.0178    | 0.0148 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5774\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.96it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6170\n",
            "\n",
            "64it [00:45,  1.41it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5939   | 0.0974    | 0.08   | 57031   |\n",
            "| known-tokens     | 0.7102   | 0.2531    | 0.2296 | 45124   |\n",
            "| unknown-tokens   | 0.1533   | 0.0555    | 0.0449 | 11907   |\n",
            "| ambiguous-tokens | 0.5664   | 0.1723    | 0.167  | 19042   |\n",
            "| unknown-targets  | 0.0269   | 0.0182    | 0.0157 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5939\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.95it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5874\n",
            "\n",
            "64it [00:47,  1.36it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6061   | 0.1073    | 0.0905 | 57031   |\n",
            "| known-tokens     | 0.7201   | 0.2746    | 0.252  | 45124   |\n",
            "| unknown-tokens   | 0.1742   | 0.0625    | 0.0521 | 11907   |\n",
            "| ambiguous-tokens | 0.5703   | 0.1928    | 0.1861 | 19042   |\n",
            "| unknown-targets  | 0.0286   | 0.0192    | 0.0172 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6061\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:33,  1.88it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5863\n",
            "\n",
            "64it [00:49,  1.30it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6099   | 0.1122    | 0.0955 | 57031   |\n",
            "| known-tokens     | 0.7226   | 0.2834    | 0.2627 | 45124   |\n",
            "| unknown-tokens   | 0.1827   | 0.066     | 0.0561 | 11907   |\n",
            "| ambiguous-tokens | 0.5613   | 0.1794    | 0.174  | 19042   |\n",
            "| unknown-targets  | 0.028    | 0.019     | 0.0173 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6099\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:33,  1.91it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5712\n",
            "\n",
            "64it [00:50,  1.27it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6211   | 0.123     | 0.1019 | 57031   |\n",
            "| known-tokens     | 0.7346   | 0.3116    | 0.2851 | 45124   |\n",
            "| unknown-tokens   | 0.1909   | 0.0756    | 0.0611 | 11907   |\n",
            "| ambiguous-tokens | 0.5819   | 0.1863    | 0.182  | 19042   |\n",
            "| unknown-targets  | 0.0308   | 0.0214    | 0.0187 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6211\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:33,  1.93it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5611\n",
            "\n",
            "64it [00:47,  1.34it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6242   | 0.1263    | 0.1067 | 57031   |\n",
            "| known-tokens     | 0.7387   | 0.3212    | 0.2978 | 45124   |\n",
            "| unknown-tokens   | 0.1899   | 0.0773    | 0.0633 | 11907   |\n",
            "| ambiguous-tokens | 0.5744   | 0.2124    | 0.2099 | 19042   |\n",
            "| unknown-targets  | 0.028    | 0.0218    | 0.0192 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6242\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.96it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5548\n",
            "\n",
            "64it [00:48,  1.31it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6272   | 0.1329    | 0.1124 | 57031   |\n",
            "| known-tokens     | 0.7378   | 0.339     | 0.3149 | 45124   |\n",
            "| unknown-tokens   | 0.208    | 0.0808    | 0.0665 | 11907   |\n",
            "| ambiguous-tokens | 0.5622   | 0.2083    | 0.2029 | 19042   |\n",
            "| unknown-targets  | 0.028    | 0.0201    | 0.0179 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6272\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  2.00it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5568\n",
            "\n",
            "64it [00:47,  1.34it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6296   | 0.1357    | 0.115  | 57031   |\n",
            "| known-tokens     | 0.7438   | 0.3503    | 0.3263 | 45124   |\n",
            "| unknown-tokens   | 0.1967   | 0.0802    | 0.0664 | 11907   |\n",
            "| ambiguous-tokens | 0.5822   | 0.2151    | 0.2075 | 19042   |\n",
            "| unknown-targets  | 0.028    | 0.0213    | 0.0191 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6296\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.95it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5545\n",
            "\n",
            "64it [00:47,  1.34it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6331   | 0.1391    | 0.1171 | 57031   |\n",
            "| known-tokens     | 0.7449   | 0.3612    | 0.3334 | 45124   |\n",
            "| unknown-tokens   | 0.2093   | 0.0833    | 0.0689 | 11907   |\n",
            "| ambiguous-tokens | 0.5713   | 0.2126    | 0.2025 | 19042   |\n",
            "| unknown-targets  | 0.0311   | 0.0236    | 0.0205 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6331\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.98it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5607\n",
            "\n",
            "64it [00:48,  1.33it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6356   | 0.1428    | 0.1222 | 57031   |\n",
            "| known-tokens     | 0.7474   | 0.3648    | 0.3394 | 45124   |\n",
            "| unknown-tokens   | 0.212    | 0.0855    | 0.0727 | 11907   |\n",
            "| ambiguous-tokens | 0.5842   | 0.1899    | 0.1891 | 19042   |\n",
            "| unknown-targets  | 0.0314   | 0.0232    | 0.0204 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6356\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.95it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5616\n",
            "\n",
            "64it [00:49,  1.29it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6288   | 0.1468    | 0.1249 | 57031   |\n",
            "| known-tokens     | 0.7383   | 0.3705    | 0.3464 | 45124   |\n",
            "| unknown-tokens   | 0.2139   | 0.0896    | 0.0743 | 11907   |\n",
            "| ambiguous-tokens | 0.553    | 0.2048    | 0.1951 | 19042   |\n",
            "| unknown-targets  | 0.0327   | 0.022     | 0.0193 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"1\" mode=\"max\" weight=\"1.0\" best=\"0.6356\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"1\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "64it [00:32,  1.95it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5632\n",
            "\n",
            "64it [00:47,  1.34it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6347   | 0.151     | 0.1295 | 57031   |\n",
            "| known-tokens     | 0.7446   | 0.3936    | 0.3643 | 45124   |\n",
            "| unknown-tokens   | 0.2182   | 0.0897    | 0.0762 | 11907   |\n",
            "| ambiguous-tokens | 0.5716   | 0.2143    | 0.206  | 19042   |\n",
            "| unknown-targets  | 0.03     | 0.0197    | 0.0179 | 3604    |\n",
            "\n",
            "Evaluating model on test set\n",
            "20it [00:16,  1.23it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.7661   | 0.2334    | 0.2229 | 17420   |\n",
            "| known-tokens     | 0.8535   | 0.4905    | 0.4764 | 15007   |\n",
            "| unknown-tokens   | 0.2225   | 0.1036    | 0.0959 | 2413    |\n",
            "| ambiguous-tokens | 0.7144   | 0.2776    | 0.2744 | 5707    |\n",
            "| unknown-targets  | 0.0317   | 0.0198    | 0.0188 | 1073    |\n",
            "\n",
            "Saved best model to: [./model-lemma-2022_03_28-20_17_58.tar]\n",
            "64it [00:48,  1.32it/s]\n",
            "Bye!\n"
          ]
        }
      ],
      "source": [
        "# 200 epoch, 30 batch size\n",
        "!pie train default_settings.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MN6Ms53c7kU",
        "outputId": "5b837d05-5201-4385-a882-d8159c74134f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "WARNING:root:\n",
            "It seems like you downloaded `pie` instead of git-cloning it or installing it with pip.\n",
            "We won't be able to check compatibility between pretrained models and `pie` version.\n",
            "\n",
            "\n",
            "::: Loaded Config :::\n",
            "\n",
            "batch_size: 25\n",
            "breakline_data: $.\n",
            "breakline_ref: ''\n",
            "buffer_size: 10000\n",
            "cache_dataset: false\n",
            "cell: LSTM\n",
            "cemb_dim: 150\n",
            "cemb_layers: 1\n",
            "cemb_type: rnn\n",
            "char_bos: true\n",
            "char_eos: true\n",
            "char_lower: false\n",
            "char_max_size: 500\n",
            "char_min_freq: 1\n",
            "checks_per_epoch: 1\n",
            "clip_norm: 5.0\n",
            "config_path: default_settings.json\n",
            "custom_cemb_cell: false\n",
            "dev_path: development_bfm.tsv\n",
            "device: cpu\n",
            "drop_diacritics: false\n",
            "dropout: 0.0\n",
            "epochs: 150\n",
            "factor: 1\n",
            "freeze_embeddings: false\n",
            "header: true\n",
            "hidden_size: 300\n",
            "include_lm: false\n",
            "init_rnn: default\n",
            "input_path: training_bfm.tsv\n",
            "linear_layers: 1\n",
            "lm_schedule:\n",
            "  factor: 0.5\n",
            "  mode: min\n",
            "  patience: 2\n",
            "  weight: 0.2\n",
            "lm_shared_softmax: true\n",
            "load_pretrained_embeddings: ''\n",
            "load_pretrained_encoder: ''\n",
            "lr: 0.001\n",
            "lr_factor: 0.75\n",
            "lr_patience: 2\n",
            "max_sent_len: 30\n",
            "max_sents: 10000\n",
            "merge_type: concat\n",
            "min_lr: 0.0001\n",
            "min_weight: 0\n",
            "minimize_pad: false\n",
            "modelname: model\n",
            "modelpath: ./\n",
            "num_layers: 1\n",
            "optimizer: Adam\n",
            "patience: 100\n",
            "pretrain_embeddings: false\n",
            "report_freq: 10\n",
            "run_test: false\n",
            "scorer: general\n",
            "sep: \"\\t\"\n",
            "shuffle: true\n",
            "task_defaults:\n",
            "  context: sentence\n",
            "  decoder: linear\n",
            "  layer: -1\n",
            "  level: token\n",
            "tasks:\n",
            "- context: none\n",
            "  decoder: attentional\n",
            "  default: copy\n",
            "  layer: -1\n",
            "  level: char\n",
            "  name: lemma\n",
            "  read_only: false\n",
            "  schedule:\n",
            "    patience: 2\n",
            "    threshold: 0.001\n",
            "  settings:\n",
            "    bos: true\n",
            "    eos: true\n",
            "    lower: true\n",
            "  target: true\n",
            "tasks_order:\n",
            "- lemma\n",
            "- pos\n",
            "test_path: test_bfm.tsv\n",
            "threshold: 0\n",
            "utfnorm: false\n",
            "utfnorm_type: NFKD\n",
            "verbose: true\n",
            "wemb_dim: 0\n",
            "word_dropout: 0.0\n",
            "word_lower: false\n",
            "word_max_size: 20000\n",
            "word_min_freq: 1\n",
            "\n",
            "Using seed: 213609\n",
            "::: Available tasks :::\n",
            "\n",
            "- cattex\n",
            "- lemma\n",
            "- pos\n",
            "\n",
            "::: Fitting data :::\n",
            "\n",
            "\n",
            "::: Vocabulary :::\n",
            "\n",
            "- word            types=20000/21174=0.94 tokens=298826/300000=1.00\n",
            "- char            types=83/83=1.00 tokens=1073024/1073024=1.00\n",
            "\n",
            "::: Tasks :::\n",
            "\n",
            "- lemma           target=lemma  level=char   vocab=66    \n",
            "\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "Model doesn't need sentence encoder, leaving uninitialized\n",
            "Initializing LSTM with scheme: xavier_uniform\n",
            "::: Model :::\n",
            "\n",
            "SimpleModel(\n",
            "  (cemb): RNNEmbedding(\n",
            "    (emb): Embedding(87, 150, padding_idx=2)\n",
            "    (rnn): LSTM(150, 150, bidirectional=True)\n",
            "  )\n",
            "  (lemma_decoder): AttentionalDecoder(\n",
            "    (embs): Embedding(66, 150)\n",
            "    (rnn): LSTM(150, 300)\n",
            "    (attn): Attention(\n",
            "      (scorer): GeneralScorer(\n",
            "        (W_a): Linear(in_features=300, out_features=300, bias=False)\n",
            "      )\n",
            "      (linear_out): Linear(in_features=600, out_features=300, bias=False)\n",
            "    )\n",
            "    (proj): Linear(in_features=300, out_features=66, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "::: Model parameters :::\n",
            "\n",
            "1217616/1217616 trainable/total\n",
            "\n",
            "Starting training\n",
            "\n",
            "Evaluation check every 399/400 batches\n",
            "\n",
            "::: Task schedules :::\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"-inf\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "::: LR schedule :::\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:31,  2.44it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.9745\n",
            "\n",
            "77it [00:44,  1.74it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.4246   | 0.0248    | 0.019  | 57031   |\n",
            "| known-tokens     | 0.5278   | 0.0637    | 0.0514 | 45124   |\n",
            "| unknown-tokens   | 0.0333   | 0.0109    | 0.0077 | 11907   |\n",
            "| ambiguous-tokens | 0.4194   | 0.0714    | 0.0717 | 19042   |\n",
            "| unknown-targets  | 0.0111   | 0.0062    | 0.0052 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.4246\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:32,  2.38it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.7714\n",
            "\n",
            "77it [00:43,  1.76it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5278   | 0.0499    | 0.0381 | 57031   |\n",
            "| known-tokens     | 0.6462   | 0.122     | 0.1063 | 45124   |\n",
            "| unknown-tokens   | 0.0793   | 0.0271    | 0.0193 | 11907   |\n",
            "| ambiguous-tokens | 0.555    | 0.1223    | 0.1208 | 19042   |\n",
            "| unknown-targets  | 0.0172   | 0.0108    | 0.0096 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5278\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:32,  2.40it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6779\n",
            "\n",
            "77it [00:43,  1.78it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5557   | 0.0723    | 0.0568 | 57031   |\n",
            "| known-tokens     | 0.6732   | 0.18      | 0.156  | 45124   |\n",
            "| unknown-tokens   | 0.1104   | 0.0408    | 0.0314 | 11907   |\n",
            "| ambiguous-tokens | 0.5382   | 0.141     | 0.1366 | 19042   |\n",
            "| unknown-targets  | 0.0513   | 0.0202    | 0.0181 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5557\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:32,  2.36it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6274\n",
            "\n",
            "77it [00:46,  1.66it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5833   | 0.0857    | 0.0681 | 57031   |\n",
            "| known-tokens     | 0.7016   | 0.2219    | 0.1975 | 45124   |\n",
            "| unknown-tokens   | 0.135    | 0.0478    | 0.0372 | 11907   |\n",
            "| ambiguous-tokens | 0.5697   | 0.1505    | 0.1485 | 19042   |\n",
            "| unknown-targets  | 0.0308   | 0.0179    | 0.0153 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5833\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:32,  2.38it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.6022\n",
            "\n",
            "77it [00:44,  1.73it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.5997   | 0.0935    | 0.0758 | 57031   |\n",
            "| known-tokens     | 0.7192   | 0.2425    | 0.2184 | 45124   |\n",
            "| unknown-tokens   | 0.1469   | 0.0552    | 0.0436 | 11907   |\n",
            "| ambiguous-tokens | 0.59     | 0.1541    | 0.1522 | 19042   |\n",
            "| unknown-targets  | 0.0341   | 0.02      | 0.0182 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.5997\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:34,  2.24it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5742\n",
            "\n",
            "77it [00:47,  1.62it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6166   | 0.1087    | 0.0873 | 57031   |\n",
            "| known-tokens     | 0.7351   | 0.2714    | 0.2472 | 45124   |\n",
            "| unknown-tokens   | 0.1673   | 0.0667    | 0.0516 | 11907   |\n",
            "| ambiguous-tokens | 0.5961   | 0.1763    | 0.1747 | 19042   |\n",
            "| unknown-targets  | 0.0369   | 0.0249    | 0.0228 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"0\" mode=\"max\" weight=\"1.0\" best=\"0.6166\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"0\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:33,  2.31it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5606\n",
            "\n",
            "77it [00:51,  1.49it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6006   | 0.1137    | 0.0926 | 57031   |\n",
            "| known-tokens     | 0.7143   | 0.295     | 0.2693 | 45124   |\n",
            "| unknown-tokens   | 0.1696   | 0.07      | 0.0551 | 11907   |\n",
            "| ambiguous-tokens | 0.5475   | 0.1861    | 0.1822 | 19042   |\n",
            "| unknown-targets  | 0.0394   | 0.0231    | 0.0215 | 3604    |\n",
            "\n",
            "<TaskScheduler patience=\"100\" factor=\"1\" threshold=\"0\" min_weight=\"0\">\n",
            "    <Task name=\"lemma\" patience=\"2\" threshold=\"0.001\" target=\"True\" steps=\"1\" mode=\"max\" weight=\"1.0\" best=\"0.6166\"/>\n",
            "</TaskScheduler>\n",
            "\n",
            "<LrScheduler lr=\"0.001\" steps=\"1\" patience=\"2\" threshold=\"0.0\"/>\n",
            "\n",
            "\n",
            "Evaluating model on dev set...\n",
            "\n",
            "77it [00:32,  2.39it/s]\n",
            "\n",
            "::: Dev losses :::\n",
            "\n",
            "lemma: 0.5472\n",
            "\n",
            "77it [00:48,  1.60it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.6096   | 0.1227    | 0.1002 | 57031   |\n",
            "| known-tokens     | 0.7194   | 0.3141    | 0.286  | 45124   |\n",
            "| unknown-tokens   | 0.1933   | 0.0771    | 0.0609 | 11907   |\n",
            "| ambiguous-tokens | 0.5478   | 0.1872    | 0.1794 | 19042   |\n",
            "| unknown-targets  | 0.0391   | 0.0251    | 0.022  | 3604    |\n",
            "\n",
            "Evaluating model on test set\n",
            "24it [00:16,  1.47it/s]\n",
            "\n",
            "## lemma\n",
            "\n",
            "|                  | accuracy | precision | recall | support |\n",
            "|------------------|----------|-----------|--------|---------|\n",
            "| all              | 0.7539   | 0.1886    | 0.1754 | 17420   |\n",
            "| known-tokens     | 0.8467   | 0.3884    | 0.3716 | 15007   |\n",
            "| unknown-tokens   | 0.177    | 0.0854    | 0.0759 | 2413    |\n",
            "| ambiguous-tokens | 0.7344   | 0.2369    | 0.2277 | 5707    |\n",
            "| unknown-targets  | 0.0289   | 0.0233    | 0.0212 | 1073    |\n",
            "\n",
            "Saved best model to: [./model-lemma-2022_03_28-23_29_17.tar]\n",
            "77it [00:47,  1.63it/s]\n",
            "Bye!\n"
          ]
        }
      ],
      "source": [
        "## new params\n",
        "##  \"epochs\": 150, // number of epochs\n",
        "##  \"batch_size\": 25, // batch size\n",
        "!pie train default_settings.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSptDFhcMcSh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "df = pd.read_csv('test_bfm.tsv', sep='\\t')\n",
        "\n",
        "test_forms = df['form'].to_list()\n",
        "with open('test_text.txt', 'w') as f:\n",
        "  f.write(' '.join(test_forms))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr3vrGSRPo3H",
        "outputId": "364cba75-9937-4944-f667-9e7bf83d2b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "WARNING:root:\n",
            "It seems like you downloaded `pie` instead of git-cloning it or installing it with pip.\n",
            "We won't be able to check compatibility between pretrained models and `pie` version.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              ""
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "cat test_text.txt | pie tag-pipe model-lemma-2022_03_28-23_29_17.tar > test_tagged_model_29-03mars.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "037p0wX6Q0SJ",
        "outputId": "70297daa-6d1b-48bc-ed6b-590238a65518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72.89896670493685\n"
          ]
        }
      ],
      "source": [
        "test_gold = 'test_bfm.tsv'\n",
        "test_pred = 'test_tagged_model_29-03mars.tsv'\n",
        "\n",
        "gold = pd.read_csv(test_gold, sep='\\t')\n",
        "\n",
        "pred = pd.read_csv(test_pred, sep='\\t', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "concated = pd.concat([gold, pred], axis=1)\n",
        "\n",
        "print(len(concated[concated.lemma == concated.lemma_pred])*100/len(concated))\n",
        "\n",
        "concated['sc'] = 0\n",
        "concated.loc[concated.lemma == concated.lemma_pred, 'sc'] = 1\n",
        "concated.groupby('pos')['sc'].mean()\n",
        "\n",
        "df_errors = concated[concated.lemma != concated.lemma_pred]\n",
        "df_errors.to_csv('test_errors29-03.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mSmu365-Wl"
      },
      "source": [
        "##Train pos **tagger**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdUapYg66A2q"
      },
      "outputs": [],
      "source": [
        "!pie train default_settings.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdVPm8p86_6a"
      },
      "source": [
        "## Test pie-extended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg-QbWIj7CCt",
        "outputId": "34cac4f5-88ac-4c11-95f2-4b65afc98464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pie-extended in /usr/local/lib/python3.7/dist-packages (0.0.39)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (1.3.4)\n",
            "Requirement already satisfied: scipy<1.6.0 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (1.4.1)\n",
            "Requirement already satisfied: PaPie==0.3.9 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (0.3.9)\n",
            "Requirement already satisfied: autodisambiguator<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (0.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pie-extended) (2019.12.20)\n",
            "Requirement already satisfied: colorama>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (0.4.4)\n",
            "Requirement already satisfied: numpy<1.18.0 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (1.17.5)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.7/dist-packages (from pie-extended) (2.27.1)\n",
            "Requirement already satisfied: torch<=1.7.1,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (1.7.1)\n",
            "Requirement already satisfied: lxml>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (4.2.6)\n",
            "Requirement already satisfied: JSON-minify>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (0.3.0)\n",
            "Requirement already satisfied: terminaltables==3.1.0 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (3.1.0)\n",
            "Requirement already satisfied: typing<4.0 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-learn<0.23.0,>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (0.22.2.post1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (1.1.0)\n",
            "Requirement already satisfied: pyyaml==5.1b3 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (5.1b3)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.23.3 in /usr/local/lib/python3.7/dist-packages (from PaPie==0.3.9->pie-extended) (4.63.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->PaPie==0.3.9->pie-extended) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->PaPie==0.3.9->pie-extended) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->pie-extended) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->pie-extended) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->pie-extended) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->pie-extended) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.23.0,>=0.19.1->PaPie==0.3.9->pie-extended) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.3.1->PaPie==0.3.9->pie-extended) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pie-extended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCzVidXULSj"
      },
      "source": [
        "* Pie-extended loads a pretained old french model but has some limitations and problems: it splits rows at certain characters making difficult to align the output to the gold annotations (need manual modification of the tokenizer script or replace those chars in the input file) and it's trained on different data\n",
        "\n",
        "* Scripts for the model:\n",
        "https://github.com/hipster-philology/nlp-pie-taggers/tree/master/pie_extended/models/fro\n",
        "\n",
        "* Related article: *Corpus and Models for Lemmatisation and POS-tagging\n",
        "of Classical French Theatre*\n",
        "https://halshs.archives-ouvertes.fr/halshs-02591388v2/document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "T5VkoUti7LTW",
        "outputId": "9c3e75a7-7b40-4f98-9872-0aae82ff0f1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c6b4b43-ab5c-4cd0-8938-b73098e2863b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>form</th>\n",
              "      <th>lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>morph</th>\n",
              "      <th>treated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sicum</td>\n",
              "      <td>Sicon</td>\n",
              "      <td>PRE</td>\n",
              "      <td>NOMB.=s</td>\n",
              "      <td>Sicum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hengist</td>\n",
              "      <td>Hengier</td>\n",
              "      <td>NOMpro</td>\n",
              "      <td>TEMPS=ipf|NOMB.=s|GENRE=m|CAS=n</td>\n",
              "      <td>Hengist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "      <td>et</td>\n",
              "      <td>CONcoo</td>\n",
              "      <td>MORPH=empty</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>li</td>\n",
              "      <td>il</td>\n",
              "      <td>DETdef</td>\n",
              "      <td>NOMB.=s|GENRE=m|CAS=n</td>\n",
              "      <td>li</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Seisun</td>\n",
              "      <td>Sesne</td>\n",
              "      <td>NOMpro</td>\n",
              "      <td>NOMB.=s|GENRE=m|CAS=n</td>\n",
              "      <td>Seisun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17834</th>\n",
              "      <td>cui</td>\n",
              "      <td>que2</td>\n",
              "      <td>PROrel</td>\n",
              "      <td>NOMB.=s|GENRE=m|CAS=i</td>\n",
              "      <td>cui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17835</th>\n",
              "      <td>sustinc</td>\n",
              "      <td>sustin</td>\n",
              "      <td>VERcjg</td>\n",
              "      <td>NOMB.=s|GENRE=m|CAS=r</td>\n",
              "      <td>sustinc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17836</th>\n",
              "      <td>tels</td>\n",
              "      <td>tel</td>\n",
              "      <td>DETind</td>\n",
              "      <td>NOMB.=p|GENRE=m|CAS=r</td>\n",
              "      <td>tels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17837</th>\n",
              "      <td>passïons</td>\n",
              "      <td>passïon</td>\n",
              "      <td>NOMcom</td>\n",
              "      <td>PERS.=1|NOMB.=p|GENRE=m</td>\n",
              "      <td>passïons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17838</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PONfrt</td>\n",
              "      <td>MORPH=empty</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17839 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c6b4b43-ab5c-4cd0-8938-b73098e2863b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c6b4b43-ab5c-4cd0-8938-b73098e2863b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c6b4b43-ab5c-4cd0-8938-b73098e2863b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           form    lemma     POS                            morph   treated\n",
              "0         Sicum    Sicon     PRE                          NOMB.=s     Sicum\n",
              "1       Hengist  Hengier  NOMpro  TEMPS=ipf|NOMB.=s|GENRE=m|CAS=n   Hengist\n",
              "2             e       et  CONcoo                      MORPH=empty         e\n",
              "3            li       il  DETdef            NOMB.=s|GENRE=m|CAS=n        li\n",
              "4        Seisun    Sesne  NOMpro            NOMB.=s|GENRE=m|CAS=n    Seisun\n",
              "...         ...      ...     ...                              ...       ...\n",
              "17834       cui     que2  PROrel            NOMB.=s|GENRE=m|CAS=i       cui\n",
              "17835   sustinc   sustin  VERcjg            NOMB.=s|GENRE=m|CAS=r   sustinc\n",
              "17836      tels      tel  DETind            NOMB.=p|GENRE=m|CAS=r      tels\n",
              "17837  passïons  passïon  NOMcom          PERS.=1|NOMB.=p|GENRE=m  passïons\n",
              "17838         .        .  PONfrt                      MORPH=empty         .\n",
              "\n",
              "[17839 rows x 5 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "from pie_extended.cli.utils import get_tagger, get_model, download\n",
        "from pie_extended.models.fro.imports import get_iterator_and_processor\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# In case you need to download\n",
        "do_download = True\n",
        "if do_download:\n",
        "    for dl in download(\"fro\"):\n",
        "        x = 1\n",
        "\n",
        "# model_path allows you to override the model loaded by another .tar\n",
        "model_name = \"fro\"\n",
        "tagger = get_tagger(model_name, batch_size=256, device=\"cpu\", model_path=None)\n",
        "\n",
        "sentences: List[str] = ' '.join(pd.read_csv('test_bfm.tsv', sep='\\t', quoting=csv.QUOTE_NONE)['form'].to_list()).split(' . ')\n",
        "\n",
        "# Get the main object from the model (: data iterator + postprocesor\n",
        "tagged_df = pd.DataFrame()\n",
        "for sent in sentences:\n",
        "  sent = sent.replace('.','').replace('·','').replace(\"l'\",'l') + ' . ' # remove these chars, Pie splits the tokens into new rows and won't align with gold data\n",
        "  iterator, processor = get_iterator_and_processor()\n",
        "  tagged = tagger.tag_str(sent, iterator=iterator, processor=processor)\n",
        "  df = pd.DataFrame(tagged)\n",
        "  tagged_df = tagged_df.append(df,ignore_index=True)\n",
        "\n",
        "tagged_df.to_csv('test_tagged_pie-extended.tsv', sep='\\t', index=None)\n",
        "tagged_df_norm = tagged_df[tagged_df.form != \"'\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdGl-nN_H7VK"
      },
      "outputs": [],
      "source": [
        "tagged_df_norm = tagged_df[tagged_df.form != \"'\"]\n",
        "len(tagged_df_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFXlrTV9wAoL"
      },
      "source": [
        "## Lemmatiser le corpus profiterole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87tNhNLjTRUH"
      },
      "source": [
        "#### Make files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9saxNfe6Dne"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import csv\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import shutil\n",
        "from subprocess import call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eikOfJqMwANG"
      },
      "outputs": [],
      "source": [
        "def get_tokens(corpus_folder):\n",
        "  ''' extract forms columns form conllu/tsv corpus files\n",
        "  '''\n",
        "  for file in glob.glob(path_corpus):\n",
        "    df = pd.read_csv(file, sep='\\t', index_col=None, quoting=csv.QUOTE_NONE, names=[range(15)])\n",
        "    df = df.reset_index()\n",
        "    df.columns = range(df.columns.size)\n",
        "    # fix problem of first column in df not starting with index\n",
        "    if df.iloc[::,0][0] == 0 or df.iloc[::,0][0] == 1 or df.iloc[::,0][0] == 2 :\n",
        "      df.iloc[::,0] = df.iloc[::,1]\n",
        "    df = df.iloc[::,0]\n",
        "    name = 'tokens/' + str(file.split('/')[-1]).replace('.tsv','').replace('.conllu','') + '_tokens.tsv'\n",
        "    df.to_csv(name, sep='\\t', index=None, header=False)\n",
        "\n",
        "path_corpus = \"corpus/*\" # path to Profiterole corpus (corpus has to be uploaded)\n",
        "get_tokens(path_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get forms from test_data\n",
        "\n",
        "test_df = pd.read_csv('test_data.tsv', sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE)\n",
        "test_df.head()\n",
        "test_df['token'].to_csv('test_tokens.tsv', sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE,\n",
        "                        header=None, index=False)"
      ],
      "metadata": {
        "id": "0PqZIWaqssyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([pd.read_csv('test_tokens_upos.tsv', sep='\\t', quoting=csv.QUOTE_NONE),\n",
        "                pd.read_csv('test_tokens_lemma.tsv', sep='\\t', quoting=csv.QUOTE_NONE)], axis=1)\n",
        "df.columns = ['form_src','pos_pred','form2','lemma_pred']\n",
        "df_merged = pd.concat([df, pd.read_csv('test_data.tsv', sep='\\t', quoting=csv.QUOTE_NONE)], axis=1)\n",
        "del df_merged['form2']\n",
        "del df_merged['form']\n",
        "df_merged.to_csv('test_lemma-pos_merged_gold.tsv', sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE, index=False)"
      ],
      "metadata": {
        "id": "WzCqdwF61O3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pass all to lowercase\n",
        "for col in df_merged.columns:\n",
        "  df_merged[col] = df_merged[col].apply(lambda x: str(x).lower())"
      ],
      "metadata": {
        "id": "wKy2FQd82U-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_score = len(df_merged[df_merged.pos_pred == df_merged.pos])*100/len(df_merged)\n",
        "lemma_score = len(df_merged[df_merged.lemma_pred == df_merged.lemma])*100/len(df_merged)\n",
        "print('Accuracy POS: ', round(pos_score, 2), '\\nAccuracy LEMMA:', round(lemma_score,2))\n",
        "\n",
        "## lemma accuracy by POS\n",
        "df_merged['score_lemma'] = 0\n",
        "df_merged.loc[df_merged.lemma_pred == df_merged.lemma, 'score_lemma'] = 1\n",
        "print(df_merged.groupby(['pos'])['score_lemma'].mean().round(2).sort_values(ascending=False))\n",
        "\n",
        "## pos accuracy by class\n",
        "df_merged['score_pos'] = 0\n",
        "df_merged.loc[df_merged.pos_pred == df_merged.pos, 'score_pos'] = 1\n",
        "print(df_merged.groupby(['pos'])['score_pos'].mean().round(2).sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKj7dTa9B_9U",
        "outputId": "fd32ea8b-4e1f-4b7e-ca11-802698abadf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy POS:  85.02 \n",
            "Accuracy LEMMA: 76.61\n",
            "pos\n",
            "cconj       1.00\n",
            "punct       1.00\n",
            "adp         0.93\n",
            "det         0.92\n",
            "sconj       0.86\n",
            "adv         0.80\n",
            "pron        0.76\n",
            "adp.det     0.63\n",
            "noun        0.63\n",
            "verb        0.62\n",
            "propn       0.43\n",
            "adj         0.39\n",
            "adp.pron    0.00\n",
            "adv.pron    0.00\n",
            "x           0.00\n",
            "Name: score_lemma, dtype: float64\n",
            "pos\n",
            "punct       1.00\n",
            "cconj       0.97\n",
            "adp         0.96\n",
            "det         0.93\n",
            "verb        0.88\n",
            "noun        0.87\n",
            "sconj       0.85\n",
            "adp.det     0.81\n",
            "propn       0.79\n",
            "adv         0.61\n",
            "pron        0.51\n",
            "adj         0.49\n",
            "adp.pron    0.00\n",
            "adv.pron    0.00\n",
            "x           0.00\n",
            "Name: score_pos, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## analyse erreurs\n",
        "errors_lemma = df_merged[df_merged.lemma_pred != df_merged.lemma]\n",
        "errors_lemma[errors_lemma.pos == 'propn']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2a_Adzf_BKA9",
        "outputId": "8a5b23e8-0988-45f5-e4b4-f795030a7f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          form_src pos_pred   lemma_pred     lemma    pos  cattex  \\\n",
              "1          hengist     verb      hangier   hengist  propn  nompro   \n",
              "4           seisun    propn       saison     saxon  propn  nompro   \n",
              "22         bretuns    propn       bretun    breton  propn  nompro   \n",
              "56            kent    propn         cent      kent  propn  nompro   \n",
              "63         hengist     verb      hangier   hengist  propn  nompro   \n",
              "...            ...      ...          ...       ...    ...     ...   \n",
              "17253    dominedeu    propn  domminetion  damedieu  propn  nompro   \n",
              "17270      ewruïns      adj     erpuison    ebroïn  propn  nompro   \n",
              "17300     lethgier     verb      letigne     léger  propn  nompro   \n",
              "17330       uadart    propn        auder    uadart  propn  nompro   \n",
              "17397  dominedieus    propn    demidieux  damedieu  propn  nompro   \n",
              "\n",
              "       score_lemma  score_pos  \n",
              "1                0          0  \n",
              "4                0          1  \n",
              "22               0          1  \n",
              "56               0          1  \n",
              "63               0          0  \n",
              "...            ...        ...  \n",
              "17253            0          1  \n",
              "17270            0          0  \n",
              "17300            0          0  \n",
              "17330            0          1  \n",
              "17397            0          1  \n",
              "\n",
              "[692 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c99fc315-f00f-473e-a35e-3da21321f4a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>form_src</th>\n",
              "      <th>pos_pred</th>\n",
              "      <th>lemma_pred</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>cattex</th>\n",
              "      <th>score_lemma</th>\n",
              "      <th>score_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hengist</td>\n",
              "      <td>verb</td>\n",
              "      <td>hangier</td>\n",
              "      <td>hengist</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>seisun</td>\n",
              "      <td>propn</td>\n",
              "      <td>saison</td>\n",
              "      <td>saxon</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>bretuns</td>\n",
              "      <td>propn</td>\n",
              "      <td>bretun</td>\n",
              "      <td>breton</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>kent</td>\n",
              "      <td>propn</td>\n",
              "      <td>cent</td>\n",
              "      <td>kent</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>hengist</td>\n",
              "      <td>verb</td>\n",
              "      <td>hangier</td>\n",
              "      <td>hengist</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17253</th>\n",
              "      <td>dominedeu</td>\n",
              "      <td>propn</td>\n",
              "      <td>domminetion</td>\n",
              "      <td>damedieu</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17270</th>\n",
              "      <td>ewruïns</td>\n",
              "      <td>adj</td>\n",
              "      <td>erpuison</td>\n",
              "      <td>ebroïn</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17300</th>\n",
              "      <td>lethgier</td>\n",
              "      <td>verb</td>\n",
              "      <td>letigne</td>\n",
              "      <td>léger</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17330</th>\n",
              "      <td>uadart</td>\n",
              "      <td>propn</td>\n",
              "      <td>auder</td>\n",
              "      <td>uadart</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17397</th>\n",
              "      <td>dominedieus</td>\n",
              "      <td>propn</td>\n",
              "      <td>demidieux</td>\n",
              "      <td>damedieu</td>\n",
              "      <td>propn</td>\n",
              "      <td>nompro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>692 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c99fc315-f00f-473e-a35e-3da21321f4a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c99fc315-f00f-473e-a35e-3da21321f4a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c99fc315-f00f-473e-a35e-3da21321f4a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcRMxz9mTXaR"
      },
      "source": [
        "#### Run lemmatization/pos-tagging on files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaB-EOtgLG-O"
      },
      "outputs": [],
      "source": [
        "def tag_lemmatize(model, tokens_folder, task):\n",
        "  ''' lemmatize/pos-tag corpus tokens\n",
        "  '''\n",
        "  for file in glob.glob(tokens_folder):\n",
        "    output_filename = file.replace('.tsv', f'_{task}')\n",
        "    call_pie = f\"cat {file} | pie tag-pipe {model} > {output_filename}\"\n",
        "    call(call_pie, shell=True)\n",
        "  shutil.make_archive('_tokens', 'zip', 'tokens') # save lemmatized/tagged tokens as zip\n",
        "\n",
        "tag_lemmatize(\"model_lemma.tar\", \"tokens/*.tsv\", \"lemmatization\")\n",
        "tag_lemmatize(\"model_upos.tar\", \"tokens/*.tsv\", \"postagging\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq_JYD1oRFeN",
        "outputId": "43eeb885-d212-45ea-e89e-563dd85fb2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "WARNING:root:\n",
            "It seems like you downloaded `pie` instead of git-cloning it or installing it with pip.\n",
            "We won't be able to check compatibility between pretrained models and `pie` version.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# to lemmatize/pos-tag single files\n",
        "!cat test_tokens.txt | pie tag-pipe model_lemmatization.tar > test_tokens_lemma.tsv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BdVPm8p86_6a"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}